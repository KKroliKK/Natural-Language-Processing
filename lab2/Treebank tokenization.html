
<!-- saved from url=(0083)https://pages.cs.wisc.edu/~coonce/cs769/hw1/Treebank_tokenization/tokenization.html -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
<title>Treebank tokenization</title>
</head>
<body data-new-gr-c-s-check-loaded="14.1094.0" data-gr-ext-installed="">

<h3>Treebank tokenization</h3>

Our tokenization is fairly simple:

<ul>
<li>most punctuation is split from adjoining words
</li><li>double quotes (<code>"</code>) are changed to doubled single
     forward- and backward- quotes (<code>``</code> and
     <code>''</code>)
</li><li>verb contractions and the Anglo-Saxon genitive of nouns
     are split into their component morphemes, and each morpheme is tagged
     separately.
     <ul>
       <li>Examples
	    <samp>
	    <ul>
	      <li> children's --&gt; children 's
	      </li><li> parents' --&gt; parents '
	      </li><li> won't --&gt; wo n't
	      </li><li> gonna --&gt; gon na
	      </li><li> I'm --&gt; I 'm
	    </li></ul>
	    </samp>
     </li></ul>
     This tokenization allows us to analyze each component
     separately, so (for example) "I" can be in the subject Noun
     Phrase while "'m" is the head of the main verb phrase.
</li><li>There are some subtleties for hyphens vs. dashes, elipsis dots (...)  and
     so on, but these often depend on the particular corpus or application
     of the tagged data.
</li><li> In parsed corpora, bracket-like characters are converted to special
     3-letter sequences, to avoid confusion with parse brackets.  Some POS
     taggers, such as <a href="http://www.cis.upenn.edu/~adwait">Adwait
     Ratnaparkhi</a>'s
     <a href="http://www.cis.upenn.edu/~adwait/statnlp.html">MXPOST</a>,
     require this form for their input.
     <br>
     In other words, these tokens in POS files:
     <samp>( ) [ ] { }</samp>
     <br>
     become, in parsed files:
     <samp>-LRB- -RRB- -RSB- -RSB- -LCB- -RCB-</samp>
     <br>(The acronyms stand for (Left|Right) (Round|Square|Curly) Bracket.)
</li></ul>
<p>
<a href="https://pages.cs.wisc.edu/~coonce/cs769/hw1/Treebank_tokenization/tokenizer.sed">
Here</a>
is a simple sed script that does a decent enough job on most corpora,
once the corpus has been formatted into one-sentence-per-line.

</p></body><grammarly-desktop-integration data-grammarly-shadow-root="true"></grammarly-desktop-integration></html>